{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade scikit-learn"
      ],
      "metadata": {
        "id": "w5oVugZjIYa8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "df = pd.read_excel(\"/content/Cust_segmentation_and_Recomendation.xlsx\")  # Replace with the path to your dataset\n",
        "\n",
        "# Convert columns to object data type\n",
        "df['Bill Payment'] = df['Bill Payment'].astype(object)\n",
        "df['Dining '] = df['Dining '].astype(object)\n",
        "df['Loan'] = df['Loan'].astype(object)\n",
        "df['Travel & hospitality '] = df['Travel & hospitality '].astype(object)\n",
        "df['Vehicle Running Expenses'] = df['Vehicle Running Expenses'].astype(object)\n",
        "df['Credit Card Payement '] = df['Credit Card Payement '].astype(object)\n",
        "df['Gym_Fitness_Centre '] = df['Gym_Fitness_Centre '].astype(object)\n",
        "df['B2B_Payment'] = df['B2B_Payment'].astype(object)\n",
        "df['High_value_Transactions_Above_25k'] = df['High_value_Transactions_Above_25k'].astype(object)\n",
        "df['Shopping '] = df['Shopping '].astype(object)\n",
        "df['Investments '] = df['Investments '].astype(object)\n",
        "df['No_of_transactions'] = df['No_of_transactions'].astype(object)\n",
        "df['Month '] = df['Month '].astype(str)\n",
        "\n",
        "\n",
        "df2 = df[['nam_branch', 'nam_cust_full', 'txt_profession_desc',\n",
        "       'nam_custadr_city', 'nam_custadr_state', 'txt_holdadr_add3',\n",
        "       'txt_cust_typ', 'risk_category', 'wealth_mng_cust', 'annual_inc_trnor',\n",
        "       'resi_type', 'nam_product', 'promotional_offers', 'Bill Payment',\n",
        "       'Dining ', 'Loan', 'Travel & hospitality ', 'Vehicle Running Expenses',\n",
        "       'Credit Card Payement ', 'Gym_Fitness_Centre ', 'B2B_Payment',\n",
        "       'High_value_Transactions_Above_25k', 'Shopping ', 'Investments ',\n",
        "       'No_of_transactions', 'Total Spent ', 'Month ', 'Customer_Value',\n",
        "       'Type_of Investor ', 'Profession', 'Frequency_of_Transactions',\n",
        "       'Type_of_Transactions']]\n",
        "\n",
        "def custom_tokenizer(text):\n",
        "    # split the text and value using regular expression\n",
        "    import re\n",
        "    pattern = re.compile(r'[a-zA-Z]+\\d+')\n",
        "    text_and_value = pattern.findall(text)\n",
        "    return text_and_value\n",
        "# Apply TF-Vectorization on data\n",
        "tfidf_payer_name = TfidfVectorizer()\n",
        "tfidf_matrix_payer_name = tfidf_payer_name.fit_transform(df2['txt_profession_desc'].astype(str))\n",
        "\n",
        "tfidf_payer_Credit_Card_Payement = TfidfVectorizer()\n",
        "tfidf_payer_Credit_Card_Payement = tfidf_payer_name.fit_transform(df2['Credit Card Payement '].astype(str))\n",
        "\n",
        "\n",
        "# Bill Payment column\n",
        "tfidf_bill_payment = TfidfVectorizer()\n",
        "tfidf_bill_payment = tfidf_bill_payment.fit_transform(df2['Bill Payment'].astype(str))\n",
        "\n",
        "# Dining column\n",
        "tfidf_dining = TfidfVectorizer()\n",
        "tfidf_dining = tfidf_dining.fit_transform(df2['Dining '].astype(str))\n",
        "\n",
        "# Loan column\n",
        "tfidf_loan = TfidfVectorizer()\n",
        "tfidf_loan = tfidf_loan.fit_transform(df2['Loan'].astype(str))\n",
        "\n",
        "# Travel & hospitality column\n",
        "tfidf_travel_hospitality = TfidfVectorizer()\n",
        "tfidf_travel_hospitality = tfidf_travel_hospitality.fit_transform(df2[ 'Travel & hospitality '].astype(str))\n",
        "\n",
        "# Vehicle Running Expenses column\n",
        "tfidf_vehicle_expenses = TfidfVectorizer()\n",
        "tfidf_vehicle_expenses = tfidf_vehicle_expenses.fit_transform(df2['Vehicle Running Expenses'].astype(str))\n",
        "\n",
        "# Gym_Fitness_Centre column\n",
        "tfidf_gym_fitness = TfidfVectorizer()\n",
        "tfidf_gym_fitness= tfidf_gym_fitness.fit_transform(df2['Gym_Fitness_Centre '].astype(str))\n",
        "\n",
        "# B2B_Payment column\n",
        "tfidf_b2b_payment = TfidfVectorizer()\n",
        "tfidf_b2b_payment = tfidf_b2b_payment.fit_transform(df2['B2B_Payment'].astype(str))\n",
        "\n",
        "# High_value_Transactions_Above_25k column\n",
        "tfidf_high_value_transactions = TfidfVectorizer()\n",
        "tfidf_high_value_transactions = tfidf_high_value_transactions.fit_transform(df2['High_value_Transactions_Above_25k'].astype(str))\n",
        "\n",
        "# Shopping column\n",
        "tfidf_shopping = TfidfVectorizer()\n",
        "tfidf_shopping = tfidf_shopping.fit_transform(df2['Shopping '].astype(str))\n",
        "\n",
        "# Investments column\n",
        "tfidf_investments = TfidfVectorizer()\n",
        "tfidf_investments= tfidf_investments.fit_transform(df2['Investments '].astype(str))\n",
        "\n",
        "# No_of_transactions column\n",
        "tfidf_no_of_transactions = TfidfVectorizer()\n",
        "tfidf_no_of_transactions = tfidf_no_of_transactions.fit_transform(df2['No_of_transactions'].astype(str))\n",
        "\n",
        "# Total Spent column\n",
        "tfidf_total_spent = TfidfVectorizer()\n",
        "tfidf_total_spent = tfidf_total_spent.fit_transform(df2[ 'Total Spent '].astype(str))\n",
        "\n",
        "\n",
        "tfidf_payee_name = TfidfVectorizer()\n",
        "tfidf_payee_name = tfidf_payee_name.fit_transform(df2['nam_custadr_city'].astype(str))\n",
        "\n",
        "tfidf_payee_account_type = TfidfVectorizer()\n",
        "tfidf_payee_account_type = tfidf_payee_account_type.fit_transform(df2['nam_custadr_state'].astype(str))\n",
        "\n",
        "tfidf_payer_account_type = TfidfVectorizer()\n",
        "tfidf_matrix_payer_account_type = tfidf_payer_account_type.fit_transform(df2['txt_cust_typ'].astype(str))\n",
        "\n",
        "tfidf_matrix = pd.concat([pd.DataFrame(tfidf_matrix_payer_name.toarray()),\n",
        "                          pd.DataFrame(tfidf_payer_Credit_Card_Payement.toarray()),\n",
        "                          pd.DataFrame(tfidf_total_spent.toarray()),\n",
        "                          pd.DataFrame(tfidf_no_of_transactions.toarray()),\n",
        "                          pd.DataFrame(tfidf_investments.toarray()),\n",
        "                          pd.DataFrame(tfidf_shopping.toarray()),\n",
        "                          pd.DataFrame(tfidf_high_value_transactions.toarray()),\n",
        "                          pd.DataFrame(tfidf_b2b_payment.toarray()),\n",
        "                          pd.DataFrame(tfidf_gym_fitness.toarray()),\n",
        "                          pd.DataFrame(tfidf_vehicle_expenses.toarray()),\n",
        "                          pd.DataFrame(tfidf_bill_payment.toarray()),\n",
        "                          pd.DataFrame(tfidf_matrix_payee_name.toarray()),\n",
        "                          pd.DataFrame(tfidf_matrix_payee_account_type.toarray()),\n",
        "                          pd.DataFrame(tfidf_matrix_payer_account_type.toarray())], axis=1)\n",
        "\n",
        "# Train test splitting\n",
        "X_train, X_test, y_train, y_test = train_test_split(tfidf_matrix,\n",
        "                                                    df2[['Customer_Value', 'Frequency_of_Transactions', 'Type_of_Transactions', 'Profession','Type_of Investor ']],\n",
        "                                                    test_size=0.2)\n",
        "\n",
        "# Fitting Random Forest Classification to the Training set\n",
        "classifier = RandomForestClassifier(n_estimators=10, criterion='entropy', random_state=42)\n",
        "multioutput_classifier = MultiOutputClassifier(classifier)\n",
        "\n",
        "multioutput_classifier.fit(X_train, y_train)\n",
        "\n",
        "y_pred = multioutput_classifier.predict(X_test)\n",
        "y_pred\n",
        "\n",
        "accuracies = [accuracy_score(y_test[col], y_pred[:, i]) for i, col in enumerate(y_test.columns)]\n",
        "mean_accuracy = np.mean(accuracies)\n",
        "\n",
        "print(\"Accuracy for each output column:\")\n",
        "for i, col in enumerate(y_test.columns):\n",
        "    print(f\"{col}: {accuracies[i]}\")\n",
        "\n",
        "print(\"Mean Accuracy:\", mean_accuracy)"
      ],
      "metadata": {
        "id": "kdJBhnkDTTrY",
        "outputId": "539c6eea-d25e-4331-9449-5f7ca2fd9f8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for each output column:\n",
            "Customer_Value: 1.0\n",
            "Frequency_of_Transactions: 1.0\n",
            "Type_of_Transactions: 1.0\n",
            "Profession: 1.0\n",
            "Type_of Investor : 1.0\n",
            "Mean Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Optimized Version\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Define the columns for tf-idf vectorization\n",
        "columns = ['txt_profession_desc', 'Credit Card Payement ', 'Total Spent ', 'No_of_transactions',\n",
        "           'Investments ', 'Shopping ', 'High_value_Transactions_Above_25k', 'B2B_Payment',\n",
        "           'Gym_Fitness_Centre ', 'Vehicle Running Expenses', 'Bill Payment', 'nam_custadr_city',\n",
        "           'nam_custadr_state', 'txt_cust_typ']\n",
        "\n",
        "# Create a dictionary to store the tf-idf vectorizers and transformed features\n",
        "tfidf_features = {}\n",
        "\n",
        "# Iterate over each column and create tf-idf vectorizers\n",
        "for column in columns:\n",
        "    tfidf_vectorizer = TfidfVectorizer()\n",
        "    tfidf_transformed = tfidf_vectorizer.fit_transform(df2[column].astype(str))\n",
        "    tfidf_features[column] = {\n",
        "        'vectorizer': tfidf_vectorizer,\n",
        "        'transformed': tfidf_transformed\n",
        "    }\n",
        "\n",
        "# Combine the tf-idf transformed features into a single DataFrame\n",
        "tfidf_matrix = pd.concat([pd.DataFrame(tfidf_features[column]['transformed'].toarray()) for column in columns], axis=1)\n",
        "\n",
        "# Train test splitting\n",
        "X_train, X_test, y_train, y_test = train_test_split(tfidf_matrix,\n",
        "                                                    df2[['Customer_Value', 'Frequency_of_Transactions',\n",
        "                                                         'Type_of_Transactions', 'Profession']],\n",
        "                                                    test_size=0.2)\n",
        "\n",
        "# Fitting Random Forest Classification to the Training set\n",
        "classifier = RandomForestClassifier(n_estimators=10, criterion='entropy', random_state=42)\n",
        "multioutput_classifier = MultiOutputClassifier(classifier)\n",
        "\n",
        "multioutput_classifier.fit(X_train, y_train)\n",
        "\n",
        "y_pred = multioutput_classifier.predict(X_test)\n",
        "\n",
        "accuracies = [accuracy_score(y_test[col], y_pred[:, i]) for i, col in enumerate(y_test.columns)]\n",
        "mean_accuracy = np.mean(accuracies)\n",
        "\n",
        "print(\"Accuracy for each output column:\")\n",
        "for i, col in enumerate(y_test.columns):\n",
        "    print(f\"{col}: {accuracies[i]}\")\n",
        "\n",
        "print(\"Mean Accuracy:\", mean_accuracy)\n"
      ],
      "metadata": {
        "id": "hQaJvoPudYtg",
        "outputId": "778fde1a-6c99-4121-cb9c-7cf130b563ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for each output column:\n",
            "Customer_Value: 1.0\n",
            "Frequency_of_Transactions: 1.0\n",
            "Type_of_Transactions: 1.0\n",
            "Profession: 1.0\n",
            "Mean Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bDd1roYhg10O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}